\section{Analyse} % (fold)
\label{sec:analyse}
\begin{comment}
	Detailierte Beschreibung der Algorithmen inkl. O-Notation (Nitty-Gritty Darstellung der Algos)
	1. ARToolKit
	2. ARToolKitPlus
	3. Zissermann/Clarke
	Analyse: Die auswertung nach den Kriterein aus Kap. Vorgehen OHNE WERTUNG! Nur die Daten erheben und auswerten.
\end{comment}

\subsection{Hirzer} % (fold)
\label{sub:hirzer}

\citeauthor{clarke96} verwenden in ihrem Verfahren ein monochromes Bildsignal $I_m$\footcite[Vgl.][S.~417]{clarke96}.
 Die Konvertierung des Bildsignals $I$ von YCbCr in $I_m$ erfolgt durch Algorithmus \ref{src:analyseConvertMonochrome}.
 Wie in Kapitel \ref{sub:farbräume} beschrieben, besteht ein YCbCr Signal aus einem Luminaz-Kanal $Y$ und den Chroma
 Abweichungen $Cb$ und $Cr$. Um ein monochromes Signal $I_m$ zu erstellen, muss der Luminanz Kanal ausgelesen und in
 einen Buffer kopiert werden.

\input{src/analyseConvertMonochrome}

Der Algorithmus verwendet als Parameter das Bildsignal $I$ und einen Pointer $I_m$ auf einen Buffer für das monochrome
 Signal. Der Monochromebuffer $I_m$ ist ein Array mit fester Größe, das beim initialisieren einmalig angelegt wird und
 danach wiederverwendet werden kann. In Zeile
 \algref{src:analyseConvertMonochrome}{src:analyseConvertMonochromeBaseaddress} wird die Adresse des Luminanz-Kanals
 $Y$ ausgelesen. Die Funktionen $width$ und $height$ liefern die Breite und Höhe des Signals in Pixeln, mit denen die
 Länge der Daten berechnet wird. Anschließend werden die Daten in den Buffer kopiert. Die Laufzeit des Algorithmus
 entspricht $\Theta(1)$. (Vorsicht: Nur Zeile 5 verwendet keine Funktionen, deren Laufzeit dir nicht bekannt sind.
 baseaddress, width und height greifen evtl. auf metadaten zurück und wären damit ein einfacher lookup mit $\Theta(1)$.
 Dann wäre nur noch memcpy zu bestimmen, was im schlimmsten Fall $\Theta(n)$ wäre.)

Um auf \gls{pixel} zugreifen zu könne, verwende ich Algorithmus \ref{src:analyseGetpixel}. Es wird der Buffer $I_m$ als
 Pointer übergeben und die Position $x$ und $y$ des gewünschten \gls{pixel}. $w$ und $h$ entsprechen der Breite und
 Höhe von $I_m$. Zeile \ref{src:analyseGetpixelStart} bis Zeile \ref{src:analyseGetpixelEnd} sorgen dafür, dass keine
 Werte außerhalb des Buffers gelesen werden können.

\input{src/analyseGetpixel}

Die Laufzeit von Algorithmus \ref{src:analyseGetpixel} ist im worst-case und im best-case konstant und somit
 $\Theta(1)$.

Der Algorithmus von \citeauthor{clarke96} ist in Algorithmus \ref{src:analyseLineDetection} aufgeführt. Zuerst wird das
 Signal $I$ in die monochrome Variante $I_m$ konvertiert. Danach wird die Breite und Höhe des Signals festgehalten. Die
 doppelte For-Schleife in Zeile \ref{src:analyseLineDetectionStart} bis \ref{src:analyseLineDetectionEnd} unterteilt
 das Signal in Regionen der Größe $40 \times 40$ \gls{pixel}, indem die Koordinate der oberen linken Ecke berechnet
 wird.

\input{src/analyseLinedetection}

In \citeauthor{clarke96} ist keine Angabe zu den Abmessungen der untersuchten Signale angegeben. Auch der Grund warum
 eine Region $40 \times 40$ \gls{pixel} gross sein muss, fehlt. Zur Analyse der Videosignale verwendeten
 \citeauthor{clarke96} einen Framegrabber 2000 der eine Auflösung von 640x480px schafft. Betrachtet man

$640 mod 40 = 0$ und $480 mod 40 = 0$

ist ersichtlich, dass die Größe der Region in der Aufteilung des Bildsignals in Zusammenhang steht.

Der Algorithmus \ref{src:analyseLineDetection} ist der zentrale Algorithmus von \citeauthor{clarke96}. Der Algorithmus
 ist verantwortlich für die Unterteilung des Bildsignals in Regionen von jeweils $40 \times 40$ \gls{pixel} (Vgl. Zeile
~\ref{src:analyseLineDetectionStart}--\ref{src:analyseLineDetectionEnd}). Die Kosten des Algorithmus können mit

\begin{equation}
\begin{split}
	T(I) = c_2
	 + c_3
	 + c_4
	 + c_5 \left[\left(\frac{h}{40}\right) + 1\right]
	 + c_6 \sum \limits_{y = 0}^{\frac{h}{40}} t_y \left[\left(\frac{w}{40}\right) + 1 \right]\\
	 + c_7 \sum \limits_{y = 0}^{\frac{h}{40}} \sum \limits_{x = 0}^{\frac{w}{40}} t_y t_x
	 + c_8 \sum \limits_{y = 0}^{\frac{h}{40}} \sum \limits_{x = 0}^{\frac{w}{40}} t_y t_x
	 + c_9 \sum \limits_{y = 0}^{\frac{h}{40}} \sum \limits_{x = 0}^{\frac{w}{40}} t_y t_x
	 + c_{11} \sum \limits_{y = 0}^{\frac{h}{40}} t_y
\end{split}
\end{equation}

dargestellt werden. Um die Gleichung zu vereinfachen führe ich $n = \tfrac{h}{40}$ und $k = \tfrac{w}{40}$ ein.

\begin{equation}
\begin{split}
	T(I) = c_2
	 + c_3
	 + c_4
	 + c_5 \left(n + 1\right)
	 + c_6 \sum \limits_{y = 0}^{n} t_y \left(k + 1 \right)\\
	 + c_7 \sum \limits_{y = 0}^{n} \sum \limits_{x = 0}^{k} t_y t_x
	 + c_8 \sum \limits_{y = 0}^{n} \sum \limits_{x = 0}^{k} t_y t_x
	 + c_9 \sum \limits_{y = 0}^{n} \sum \limits_{x = 0}^{k} t_y t_x
	 + c_{11} \sum \limits_{y = 0}^{n} t_y
\end{split}
\end{equation}

Sowohl bei worst-case als auch bei best-case werden die Summen immer vollständig durchlaufen. Damit kann die Gleichung
 zu

\begin{equation}
\begin{split}
	T(I) = c_2
	 + c_3
	 + c_4
	 + c_5 \left(n + 1\right)
	 + c_6 \left[n \left(k + 1 \right)\right]
	 + c_7 n k
	 + c_8 n k
	 + c_9 n k
	 + c_{11} n\\
	= c_2 + c_3 + c_4 + c_5
	+ \left(c_5 + c_6 + c_{11}\right) n
	+ \left(c_6 + c_7 + c_8 + c_9\right) n k
\end{split}
\end{equation}

vereinfacht werden und ergibt eine Laufzeit von $\Theta(nk)$.

Das Verfahren zur Bestimmung der Edgels benötigt das monochrome Bildsignal $I_m$, sowie die Position der oberen linken
 Ecke der Region, die durch oben $t$ und links $l$ definiert ist. Die Breite und Höhe der Region ist durch $rw$ und
 $rh$ angegeben. Die Abmessung des Bildsignals werden als $w$ und $h$ bezeichnet.

\input{src/analyseFindedgels}

Zeile~\ref{src:analyseFindedgelsHorizontalScanlineStart}--\ref{src:analyseFindedgelsHorizontalScanlineEnd} ist für den
 Aufbau der horizontalen Scanlines verantwortlich. Die Überprüfung sorgt dafür, dass die Scanlines bis zum Ende der
 Region im Abstand von $5$ Pixeln untersucht werden. Nach der Initialisierung der Variablen wird in der Schleife von
 Zeile~\ref{src:analyseFindedgelsLoop2Start}--\ref{src:analyseFindedgelsLoop2End} jeder Pixel auf der Scanline
 untersucht. Zuerst wird in Zeile~\ref{src:analyseFindedgelsConvolute} die Faltung mit einem Gauß-Kernel vorgenommen
 (Vgl. Algorithmus \ref{src:analyseConvolution} S.~\pageref{src:analyseConvolution}). Der Test in Zeile~\ref
{src:analyseFindedgelsFoundEdgel} überprüft anschließend das Ergebnis der Faltung. Wenn der Schwellwert nicht
 überschritten wird, gibt es keinen genügend großen Anstieg des Gradienten und das Ergbnis wird auf $0$ gesetzt. Wird
 der Schwellwert überschritten, handelt es sich um einen Edgel und das Ergbnis wird in den Bedingungen von Zeile~\ref
{src:analyseFindedgelsLocalMaxima} weiter untersucht, ob es sich um ein lokales Maximum handelt. Ein lokales Maximum
 bedeutet, dass ein Edgel einen größeren Gradienten besitzt als seine beiden Nachbarn.

Die Bedingung in Zeile~\ref{src:analyseFindedgelsLocalMaxima} wird bei der ersten Überprüfung immer fehlschlagen.
 Dadurch wird sichergestellt, dass kein Maxium an den Rändern existiert, da hier nicht genügend Nachbarn vorhanden sind
 um eine verlässliche Aussage zu treffen. Zeile~\ref{src:analyseFindedgelsCopy1} und
 Zeile~\ref{src:analyseFindedgelsCopy2} kopieren die Werte für den nächsten Durchlauf. Durch das kopieren der Werte
 werden die Nachbarn für den nächsten Durchlauf um eine Position weiterverschoben. Nur bei einem lokalen Maximum wird
 die Position des Edgels gespeichert, und seine Orientierung (Vlg. Algorithmus \ref{src:analyseOrientation}
 S.~\pageref{src:analyseOrientation}) berechnet. Der Edgel wird in (einer Liste|einem Memorypool) zu weiteren
 Verarbeitung gespeichert.

Sind alle Pixel auf einer Scanline untersucht, wird in Zeile~\ref{src:analyseFindedgelsIncrementScanline} die nächste
 Scanline ausgewählt. Das Verfahren wird solange wiederholt, bis alle Scanlines innerhalb der Region untersucht wurden.

In Zeile~\ref{src:analyseFindedgelsVerticalScanlineStart}--\ref{src:analyseFindedgelsVerticalScanlineEnd} werden wie in
 Zeile~\ref{src:analyseFindedgelsHorizontalScanlineStart}--\ref{src:analyseFindedgelsHorizontalScanlineEnd} die
 vertikalen Scanlines untersucht.


In Algorithmus~\autoref{src:analyseConvolution} wird durch Faltung mit dem Gauß-Kernel
$\left( \begin{smallmatrix}
-3& -5& 0& 5& 3
\end{smallmatrix} \right)$
der Gradient berechnet.

\input{src/analyseConvolute}

In \citeauthor{clarke96}\footcite[Vgl.][S.~417]{clarke96} wird das Ergebnis der Faltung mit $\tfrac{1}{16}$
 multipliziert. Dadurch wird erreicht, dass die berechneten Werte dem Wertebereichs des monochromen Bildes entsprechen.
 Der maximale Wert entspricht
$\tfrac{1}{16}
\cdot
\left( \begin{smallmatrix}
	-3& -5& 0& 5& 3
\end{smallmatrix} \right)
\cdot
\left( \begin{smallmatrix}
	0& 0& 0& 255& 255
\end{smallmatrix} \right)
= 127.5
$
und der minimale Wert entspricht
$\tfrac{1}{16}
\cdot
\left( \begin{smallmatrix}
	-3& -5& 0& 5& 3
\end{smallmatrix} \right)
\cdot
\left( \begin{smallmatrix}
	255& 255& 0& 0& 0
\end{smallmatrix} \right)
= -127.5 \text{.}
$


\input{src/analyseOrientation}
\input{src/analyseNormalizedvector}
% subsection hirzer (end)

% section analyse (end)