\section{Untersuchungsgegenstand: Tracking Verfahren und Tracking Algorithmen} % (fold)
\label{sec:untersuchungsgegenstand}
\begin{comment}
	Untersuchungsgegenstand: Verfahren und Algorithmen präzise vorstellen und ihre Unterschiede hervorheben.
	Notwendige Kriterien der Algorithmen bestimmen

	Grober Ablauf der Verfahren:
	* Wer hats erfunden?
	* Wie ist das Verfahren aufgebaut (Algo in grob)
	* Welche Kriterien müssen erfüllt sein (monochrom, rgb eingabe)?
\end{comment}

\subsection{ARToolKitPlus} % (fold)
\label{sub:artoolkitplus}

ARToolKitPlus ist die Weiterentwicklung von ARToolKit von \citeauthor{wagner07b}. ARToolKitPlus verwendet zur
Identifizierung von Marken eine \textit{Runtime Tracking Pipeline} bestehend aus den fünf Stufen:

\begin{enumerate}
	\item Fiducial Detection, \label{fiducialdetection}
	\item Rectangle Fitting, \label{rectanglefitting}
	\item Pattern Checking,
	\item Lens Undistortion und
	\item Pose Estimation.
\end{enumerate}

ARToolKitPlus erkennt Marken, indem in einem Binärbild Kanten gesucht werden um daraus zusammenhängende Bildregionen
 zu erstellen. Diese Regionen werden isoliert betrachtet und daraufhin untersucht, ob es sich dabei um ein Rechteck
 handelt. Dazu wird \autoref{fiducialdetection} und \autoref{rectanglefitting} aus der
 \textit{Runtime Tracking Pipeline} verwendet.


\subsubsection{Fiducial Detection} % (fold)
\label{sub:fiducial_detection}

Fiducial Detection sorgt mit zwei Verfahren für die Eingrenzung der Bilddaten auf Bereiche in denen eine Marke sein könnte. Dazu müssen zuerst zusammenhängende Bildregionen identifiziert werden, um im Anschluss die Umrisse der Regionen zu berechnen.

Im Idealfall ist eine Marke eine zusammenhängende Region von schwarzen Pixeln in einem Binärbild, die es zu finden
 gilt. ARToolKitPlus benutzt zur Erkennung von zusammenhängenden Bildregionen eine abgewandelte Form der sequentiellen
 Regionenmarkierung (Vgl. \autoref{sec:regionen_in_binärbilder}). Im Unterschied zum bereits vorgestellten Verfahren,
 integriert ARToolKitPlus die Erstellung eines Binärbild, durch eine Schwellwertanalyse, in das Verfahren der
 Regionenmakierung. Dazu wird das Bildsignal zeilenweise von links oben nach rechts unten \gls{pixel} für \gls{pixel}
 untersucht. Wenn der Wert eines \gls{pixel} dabei über einem Schwellwert liegt, handelt es sich um einen
 Hintergrundpixel. Andernfalls, wenn der Wert kleiner als der Schwellwert ist, handelt es sich um einen
 Vordergrundpixel.

Zur Erkennung einer Bildregion ist ein Hintergrundpixel nicht von Bedeutung und wird an Position $(u,v)$ als $0$ gespeichert. Da ARToolKitPlus ein Binärbild während der Regionenmarkierung erstellt, wird auf eine expliziete Speicherung eines Vordergrundpixel verzichetet. Somit verwendet ARToolKitPlus folgende numerischen Werte zur Markierung:

\begin{equation*}
	I(u,v) = \begin{cases}
	0 & \textrm{Hintergrund}\\
	1,2\ldots,n & \textrm{Regionenmakierung}
	\end{cases}
\end{equation*}

Bei einem Vordergrundpixel wird die Beziehung des \gls{pixel} zu seinen Nachbarn durch eine 8er-Nachbarschaft
 untersucht. Bei der Zuweisung einer Markierung unterscheidet sich ARToolKitPlus von dem Verfahren in
 \autoref{sec:regionen_in_binärbilder}. Eine Kollision der Markierung durch unterschiedliche Markierungen der Nachbarn
 wird direkt verarbeite. Dazu werden die numerischen Werte der Makierungen verglichen und alle größeren Werte durch die
 Markierung mit kleinerem Wert überschrieben. Dadurch müssen Kollisionen nicht in einem zusätzlichen Schritt aufgelöst
 werden. Dabei ist zu erwähnen, dass die Markierungen im Bildspeicher nicht ersetzt werden. ARToolKitPlus speichert die
 Information der Markierungen in einer eigenen Liste (Vgl. \autoref{fig:}).

Nachdem das Eingangssignal vollständig markiert wurde, enthält die Liste mit Markierungen duch aufgetretene Kollisionen
 keine fortlaufenden Werte. Um eine Liste mit fortlaufenden Markierungswerten zu erhalten, wird die Liste für jede
 Markierung durchlaufen. Dabei wird unterschieden, ob der aktuelle Wert der Laufvariable entspricht, falls dem so ist,
 wird die Laufvarible in der Liste gespeichert. Andernfalls wird der vorherige Wert der List an die aktuelle Position
 geschrieben. \autoref{fig:} verdeutlicht diesen Vorgang.

Anstatt die Regionen anhand ihrer Markierungen im Eingangssignal zu speichern, verwendet ARToolKitPlus dazu eine eigene
 Speicherbereich. Eine Region besteht in ARToolKitPlus aus der Markierung, der Start- und Endposition der Region, des
 Flächeninhalts der Region und den Koordinaten des Zentrums. Diese Daten werden mithilfe der Liste der Markierungen
 generiert und wird in \autoref{sec:} erläutert.

\begin{comment}
	TODO: arGetContour gehört auch noch dazu (8er Nachbarschaft)
	Wenn der Algorithmus eine geschlossene Gruppe von Pixeln gefunden
	 hat, wird die Gruppe zur weiteren Verarbeitung gespeichert. Falls es sich um eine offene Gruppe von Pixeln
	 handelt, wird die Gruppe verworfen, da sie sich nicht zur Erkennung eignet\footcite[Vgl.][S.~41--42]{wagner07a}.
\end{comment}

% subsubsection fiducial_detection (end)


\subsubsection{Rectangle Fitting} % (fold)
\label{sub:rectangle_fitting}

In diesem Schritt wird eine Gruppe untersucht, ob es sich um ein Rechteck, und somit eine Marke, handelt.
 \citeauthor{wagner07a} definiert ein Rechteck als eine 2D Struktur mit vier fast geraden Linien, die durch
 Überschneidung vier Eckpunkte bilden\footcite[Vgl.][S.~42]{wagner07a}.

Das Verfahren wählt einen \gls{pixel} als Startpunkt und berechnet für alle anderen \gls{pixel} den Abstand. Das
 \gls{pixel} mit dem grössten Abstand ist eine erste Ecke. Anschliessend wird eine Linie zwischen dem Startpunkt und
 des ersten Eckpunktes definiert, um den Abstand aller Pixel zu dieser Geraden zu berechnen. Dadurch findet das
 Verfahren eine Ecke auf jeder Seite der Geraden, wenn der Abstand eines \gls{pixel} größer als ein festgelegter
 Schwellwert ist.

\begin{comment}
	- Eckpunkte entlang der Region finden
	 - Abbruch: keine ecken mehr oder mehr als 4 ecken
	- Nur exakt 4 ecken sind ein rechteck

	Eckpunkte finden:
	- Wähle ersten Pixel aus und berechne die Distanz aller anderen Pixel
	- der Punkt mit der größten Distanz ist ein erster Eckpunkt
	- Untersuche alle Pixel zwischen dem ersten Pixel und ersten Eckpunkt, Pixel mit größtem Abstand ist ein weiterer Eckpunkt
	- rekursiv wiederholen, für linke seite/rechte seite
\end{comment}

% subsubsection rectangle_fitting (end)

% subsection artoolkitplus (end)


\subsection{Verfahren nach Hirzer} % (fold)
\label{sub:verfahren_nach_hirzer}

Der Algorithmus von \citeauthor{hirzer08}\footcite{hirzer08} ist nach dem Vorbild der \textit{pixel connectivity edge
 linking based algorithms} entworfen und ist in drei Hauptteile aufgebaut. Zuerst werden Liniensegmente erstellt,
 indem \glspl{edgel} auf einem Suchraster gefunden und zusammengeführt werden. Die kurzen Liniensegmente werden dann zu
 längeren Linien zusammengeführt. Anschließend werden im zweiten Schritt alle gefundenen Linien erweitert um die
 Gesamtlänge einer Linie zu erhalten. Im letzten Schritt werden die Linien zu Vierecken verbunden. Im weiteren Verlauf
 werden diese Schritte als Line Detection, Line Extension und Quadrangle Detection bezeichnet.

\subsubsection{Line Detection} % (fold)
\label{sub:line_detection}
Die Linienerkennung basiert auf dem Verfahren von \citeauthor{clarke96}\footcite{clarke96} und besteht aus zwei
 Schritten. Im ersten Schritt wird das Bildsignal grob abgetastet um im zweiten Schritt durch das RANSAC Verfahren eine
 Linienhypothese zu erstellen und zu bewerten.

Im ersten Schritt wird zuerst das monochrome Eingabesignal $I_m$ in $40 \times 40$ \gls{pixel} große Regionen
 unterteilt. Jede nachfolgende Operation erfolgt innerhalb einer Region. Eine Region wird wiederum unterteilt in
 horizontale und vertikale Scanlines, die jeweils $5$ \gls{pixel} Abstand zueinander haben. Jedes \gls{pixel} auf den
 Scanlines wird mit einem Gauß-Kernel gefaltet um die Komponente des Gradienten zu bestimmen. Ein lokales Maximum des
 Gradienten, dass größer als ein festgelegter Schwellwert ist, wird als \gls{edgel} betrachtet und seine Orientierung
 berechnet.

Im zweiten Schritt wird das RANSAC Verfahren verwendet, um aus der Menge der \glspl{edgel} Liniensegmente zu bestimmen.
 Eine Linienhypothese wird durch die zufällige Auswahl zweier \glspl{edgel} erstellt, deren Orientierung innerhalb
 eines Grenzwert liegen müssen. Ein \gls{edgel} dient als Startpunkt und das andere \gls{edgel} als Endpunkt der Linie.
 Im Anschluss wird die Anzahl der \glspl{edgel} betrachtet, die in der Nähe dieser Linie liegen und eine kompatible
 Orientierung mit der Linie aufweisen. Diese \glspl{edgel} unterstützen die Hypothese einer Linie im Bildsignal, wenn
 die Anzahl größer ist als die minimal geforderte Anzahl von Unterstützungsedgels. Die zufällige Auswahl zweier
 \glspl{edgel} um eine Linie zu erstellen und deren Edgelunterstützung zu ermitteln wird mehrmals wiederholt um die
 Linie mit der meisten Edgelunterstützung zu finden. Wenn eine solche dominante Linie gefunden wurde, gilt die
 Hypothese als bestätigt und die Linie wird als vorhanden betrachtet. Die Edgels die zur Unterstüztung der Hypothese
 der Linie galten, werden aus der Menge der Edgels entfernt und das Verfahren wird solange wiederholt, bis alle
 Liniensegmente gefunden wurden oder nicht mehr genügend Edgels vorhanden sind.

Das Verfahren ist in \autoref{alg:linedetection-clarke} dargestellt.

\input{alg/linedetection-clarke}

\citeauthor{hirzer08} hat das Verfahren von \citeauthor{clarke96} abgewandelt, um es zur Erkennung einer bitonalen
 Marke zu nutzen. Dazu verwendet \citeauthor{hirzer08}, anstatt eines monochromen Bildsignals, ein farbiges Bildsignal
 und untersucht zuerst einen der drei Farbkanäle. Wenn ein \gls{edgel} in einem Kanal gefunden wird, werden die
 verbleibenden Kanäle untersucht, um sicherzustellen, dass auch hier ein \gls{edgel} vorliegt. Ist der Gradient in
 allen drei Kanälen höher als der festgelegte Schwellwert, handelt es sich um einen Übergang  von Schwarz nach Weiß.
 Ist dies nicht der Fall, handelt es sich um einen farbigen Übergang und ist somit zur Erkennung einer Marke
 uninteressant. Da ein monochromes Signal wie in \autoref{sub:bildtypen} beschrieben nur ein Kanal besitzt, kann hier
 diese Unterscheidung nicht getroffen werden, was zu einer größeren Anzahl von \glspl{edgel}
 führt\footcite[Vgl.][S.~6--7]{hirzer08}.

\input{alg/linemerging-hirzer}

Das vorgestellte Verfahren von \citeauthor{clarke96} liefert als Ergebnis nur kurze Liniensegmente. Um eine Kante
 entlang einer Marke zu erkennen, müssen die kurzen Liniensegmente zusammengeführt werden
 (Vgl. \autoref{alg:linemerging-hirzer}). Dazu werden alle Liniensegmente miteinander verglichen um jede
 Kombinationsmöglichkeit zu testen. Ob zwei Liniensegmente zu einer Linie zusammengeführt werden können, ist von drei
 Kriterien abhängig. Zuerst müssen zwei Liniensegmente eine kompatible Orientierung aufweisen, die nur geringfügig
 abweichen darf um als Ergebnis eine gerade Linien zu erhalten. Als zweites Kriterium muss eine Verbindungslinie
 zwischen den Liniensegmenten ebenfalls eine kompatible Orientierung aufweisen. Dadurch wird sichergestellt, dass keine
 Liniensegmente zusammengeführt werden, die zwar eine kompatible Orientierung besitzen aber parallel zueinander liegen.
 Als letztes Kriterium wird der Gradient der Verbindungslinie Punkt für Punkt untersucht. Dieses Kriterium dient dazu
 nebeneinanderliegende Marken zu unterscheiden. Würde man dies Unterscheidung vernachlässigen, würden mehrere Kanten
 unterschiedlicher Marken zusammengeführt (Vgl.~\autoref{fig:linemerging-kriterium3}).

\begin{figure}[!ht]
	\centering
	\subfigure[]{
		\label{fig:linemerging-1}
		\includegraphics[scale=1]{resources/Linemerging-1.pdf}
	}
	\subfigure[]{
		\label{fig:linemerging-2}
		\includegraphics[scale=1]{resources/Linemerging-2.pdf}
	}
	\caption{Überprüfung des Gradienten. Wird der Gradient der Verbindungslinie nicht untersucht, werden Liniensegmente
	 verbunden, die zu unterschiedlichen Marken gehören, wie in \subref{fig:linemerging-1} dargestellt. In
	 \subref{fig:linemerging-2} wurde der Gradient der Verbindungslinie untersucht und zwei Linien erkannt.}
	\label{fig:linemerging-kriterium3}
\end{figure}

\citeauthor{hirzer08} verwendet keinen Schwellwert um einen minimalen oder maximalen Abstand zwischen zwei
 Liniensegmenten festzulegen. \citeauthor{hirzer08} begründet dies Entscheidung damit, dass bei einem zu kleinen
 Schwellwert Liniensegmente, die zu weit auseinander liegen, nicht zusammengeführt werden, obwohl sie zusammengehören.
 Wird der Abstand des Schwellwerts aber zu groß gewählt, werden Liniensegmente zusammengeführt, die nicht
 zusammengehören. Um auf einen Distanzschwellwert verzichten zu können, werden die Liniensegmente sortiert, so dass
 Liniensegmente mit kurzen Verbindungslinien zuerst zusammengeführt werden. Dadurch kann sichergestellt werden, dass
 Liniensegmente zusammengeführt werden die nah beieinander liegen.

Das Zusammenführen der Liniensegmente wird zweimal durchgeführt. Zuerst innerhalb einer Region um alle kurzen
 Liniensegmente zu verbinden. Nachdem innerhalb aller Regionen Liniensegmente zusammengeführt wurden, wird der Vorgang
 auf dem gesamten Bildsignal wiederholt um größere Liniensegmente zu vereinen. Dadurch müssen nicht alle
 Liniensegmente-Kombinationen im gesamten Bildsignal verglichen werden, was die Laufzeit
 reduziert\footcite[Vgl.][S.~10]{hirzer08}.

% subsubsection line_detection (end)

\subsubsection{Line Extension} % (fold)
\label{sub:line_extension}

\input{alg/lineextension-hirzer}

Nach der Anwendung von Line Detection erhalten wir als Ergebnis Linien. Diese Linien repräsentieren aber nicht eine
 tatsächliche vorhandene Kante im Bildsignal. In den meisten Fällen fehlt am Anfang oder Ende einer Linie ein Stück.
 Mit Line Extension wird versucht die fehlenden Stücke am Anfang und am Ende einer Linie zu erweitern, um damit eine
 vollständige Linie abzubilden (Vgl. \autoref{alg:lineextension-hirzer}).

Um Linien zu erweitern, wird jede Linie \gls{pixel} für \gls{pixel} untersucht. Dabei wird an einem Ende der Linie
 ein \gls{pixel} weitergerückt und die Orientierung dieses \gls{pixel} mit der Orientierung der Linie verglichen. Falls
 die Orientierung kompatibel ist, wird der Endpunkt der Linie durch das hinzugefügte \gls{pixel} ersetzt. Das Verfahren
 wird solange wiederholt, bis die Orientierung nicht mehr übereinstimmt. Das bedeutet, dass sich der Gradient zu stark
 verändert hat und dadurch das Ende einer Kante gefunden wurde. Somit ist eine Seite der Linie erweitert und das
 Verfahren wird für das andere Ende der Linie wiederholt.

Zusätzlich wird überprüft, ob über das Ende der erweiterten Linie hinaus ein heller \gls{pixel} liegt. Wenn dem so ist,
 eignet sich diese Linie zur Erkennung von Eckpunkten und somit zur Erkennung von Marken. Sollte sich über das Ende der
 Linie hinaus kein heller \gls{pixel} befinden, liegt eine Ecke der Marke entweder außerhalb des Bildes oder ist
 verdeckt und eignet sich somit nicht zu Erkennung einer Marke. Das Verfahren wird auf beiden Enden einer Linie
 angewendet. Falls beide Enden sich nicht zur Erkennung von Eckpunkten eignen, wird die Linie entfernt.
% subsubsection line_extension (end)

\subsubsection{Quadrangle Detection} % (fold)
\label{sub:quadrangle_detection}

Um aus den gefundenen Linien eine quadratische Marke zu erkennen, werden Eckpunkte gesucht, die durch Überkreuzung der
 Linien entstehen. Dies wird durch Quadrangle Detection erreicht indem alle Linienkombinationen untersucht werden um
 vier Eckpunkte zu finden.

\input{alg/quadrangledetection-hirzer}

\autoref{alg:quadrangledetection-hirzer} vergleicht alle Linienkombinationen auf drei Kriterien. Zuerst dürfen zwei
 Linien nicht parallel zueinander liegen, da sonst keine quadratische Marke gefunden werden kann. Danach wird als
 zweites Kriterium der Abstand der Linienenden untersucht. Bleibt der Abstand unter einem festgelegten Schwellwert,
 wird das Verfahren fortgesetzt. Zuletzt wird die Orientierung der beiden Linien untersucht. Eine quadratische Marke
 besteht aus einem schwarzen Rahmen auf weißem Untergund und wird dadurch von den Linien eingeschlossen
 (Vgl.~\autoref{sub:bitonalemarken}). Somit muss die Orientierung der Linien sich um $90^\circ$ unterscheiden. Wenn
 alle drei Kriterien erfüllt sind, wird der Überschneidungspunkt der Linien als Eckpunkt der Marke gespeichert und das
 Verfahren mit der zweiten Linien rekursiv wiederholt bis vier Eckpunkte gefunden wurden. Falls weniger als vier
 Eckpunkte gefunden wurden, wird das Verfahren am anderen Ende der ersten Linie wiederholt. Dadurch wird
 sichergestellt, dass die Eckpunkte durch eine Kette von Linien verbunden sind. Idealerweise wird eine geschlossene
 Kette mit vier Eckpunkten gefunden.

Falls vier Eckpunkte gefunden wurden, wurde eine vollständiges Quadrat entdeckt und somit eine Marke erkannt. Wurden
 weniger als vier Eckpunkte gefunden, kann das Quadrat wiederhergestellt werden. Mit drei Eckpunkten ist es möglich den
 fehlenden Eckpunkt zu berechnen, indem die beiden Linien an der Lücke überkreuzt werden. Laut Hirzer ist das Ergebnis in
 den meisten Fällen akurat\footcite[Vgl.][S.15]{hirzer08}. Falls nur zwei Eckpunkte gefunden wurden, werden die
 Linienenden an der Lücke zusammengeschlossen. Das Ergebnis variert je nach Qualität der vorrausgegangen Line
 Extension. Im Falle einer guten Linienerweiterung ist das Ergebnis genau. Doch im Falle einer schlechten Erweiterung
 ist das Ergebnis ungenau (Vgl.~\autoref{fig:quadrangledetection}). Wenn nur ein Eckpunkt gefunden wurde, ist eine
 Wiederherstellung der Marke nicht möglich und die Linien werden gelöscht.

\begin{figure}[!ht]
	\centering
	\subfigure[]{
		\includegraphics[scale=1]{resources/QuadrangleDetection-Good.pdf}
		\label{fig:quadrangledetection-good}
	}
	\subfigure[]{
		\includegraphics[scale=1]{resources/QuadrangleDetection-Bad.pdf}
		\label{fig:quadrangledetection-bad}
	}
	\caption{Wiederherstellung der Marke mit zwei Eckpunkten (grün dargestellt).
	 \subref{fig:quadrangledetection-good} Qualität der Linien (Rot) ist gut um damit eine Erkennung der Marke zu
	 ermöglichen. \subref{fig:quadrangledetection-bad} Die rechte Linie ist deutlich kürzer als die linke Linie. Eine
	 Verbindungslinie zwischen den beiden Enden liefert eine schlechte Repräsentation der Marke.}
	\label{fig:quadrangledetection}
\end{figure}

% subsubsection quadrangle_detection (end)

\begin{comment}
	Der RANSAC Grouper wird verwendet um gerade Liniensegmente zu finden. Dazu werden zwei zufällige edgels ausgewählt
	 und ihre kompatible Orientierung überprüft. Die Anzahl der supporting edgels wird durch die Distanz des
	 Liniensegments und der Orientierung bestimmt. Durch wiederholung dieses Prozesses wird die dominante Linie in der
	 Region bestimmt. Die supporting edgels werden entfernt und der Prozess wird wiederholt bis keine edgels mehr
	 vorhanden sind oder eine maximale Anzahl von wiederholungen erreicht wurde. Durch dieses Wiederholung wird
	 sichergestellt, dass alle dominanten Linien in einer Region erkannt werden.

	Vorteil: Der Algorithmus ist sehr schnell und lässt sich für gewünschte Liniensegmente anpassen.
	Nachteil: Durch sein antisotropic detection verhalten diskriminiert das verfahren diagonale liniensegmente. Dies
	 ist durch ein rechteckiges samplingrid bedingt.

	Hirzer hat das Verfahren um zwei Punkte erweitert und angepasst.
	Wird in einem RGB Bild ein Kanal untersucht und ein Edgel gefunden, werden in den restlichen zwei Kanälen an der
	 gleichen Position nach einem Edgel gesucht. Falls in allen drei Kanälen ein Edgel gefunden wird, handelt es sich
	 um ein Linie (Schwarz/Weiß) und keine Farblinie.

	Nur das erste Frame wird vollständig untersucht und die Position der gefundenen Marken notiert. In den folgenden
	 frames wird nur in den Regionen der gefundenen Marke das Verfahren benutzt. Erst nach einer festgelegten Anzahl
	 von frames wird wieder ein vollständiger Durchlauf des Verfahrens durchgeführt.
\end{comment}

% subsection verfahren_nach_hirzer (end)

% section section_name (end)
